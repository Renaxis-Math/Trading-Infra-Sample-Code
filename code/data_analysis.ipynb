{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Hoang Chu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiofiles==22.1.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 1)) (22.1.0)\n",
      "Requirement already satisfied: aiosqlite==0.18.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: anyio==3.6.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 3)) (3.6.2)\n",
      "Requirement already satisfied: appnope==0.1.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 4)) (0.1.3)\n",
      "Requirement already satisfied: argon2-cffi==21.3.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 5)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 6)) (21.2.0)\n",
      "Requirement already satisfied: arrow==1.2.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 7)) (1.2.3)\n",
      "Requirement already satisfied: asttokens==2.2.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: attrs==22.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 9)) (22.2.0)\n",
      "Requirement already satisfied: Babel==2.12.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 10)) (2.12.1)\n",
      "Requirement already satisfied: backcall==0.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: bardapi==0.1.38 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 12)) (0.1.38)\n",
      "Requirement already satisfied: beautifulsoup4==4.11.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 13)) (4.11.2)\n",
      "Requirement already satisfied: bleach==6.0.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 14)) (6.0.0)\n",
      "Requirement already satisfied: browser-cookie3==0.19.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 15)) (0.19.1)\n",
      "Requirement already satisfied: cachetools==5.3.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 16)) (5.3.2)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 17)) (2022.12.7)\n",
      "Requirement already satisfied: cffi==1.15.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 18)) (1.15.1)\n",
      "Requirement already satisfied: charset-normalizer==3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 19)) (3.1.0)\n",
      "Requirement already satisfied: colorama==0.4.6 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.1.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 21)) (0.1.2)\n",
      "Requirement already satisfied: contourpy==1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 22)) (1.1.1)\n",
      "Requirement already satisfied: cycler==0.11.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 23)) (0.11.0)\n",
      "Requirement already satisfied: debugpy==1.6.6 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 24)) (1.6.6)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 25)) (5.1.1)\n",
      "Requirement already satisfied: deep-translator==1.11.4 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 26)) (1.11.4)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 27)) (0.7.1)\n",
      "Requirement already satisfied: executing==1.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.16.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 29)) (2.16.3)\n",
      "Requirement already satisfied: fonttools==4.42.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 30)) (4.42.1)\n",
      "Requirement already satisfied: fqdn==1.5.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 31)) (1.5.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 32)) (0.3.3)\n",
      "Requirement already satisfied: google-api-core==2.12.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 33)) (2.12.0)\n",
      "Requirement already satisfied: google-auth==2.23.4 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 34)) (2.23.4)\n",
      "Requirement already satisfied: google-cloud-core==2.3.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 35)) (2.3.3)\n",
      "Requirement already satisfied: google-cloud-translate==3.12.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 36)) (3.12.1)\n",
      "Requirement already satisfied: google-generativeai==0.2.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 37)) (0.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos==1.61.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 38)) (1.61.0)\n",
      "Requirement already satisfied: grpcio==1.59.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 39)) (1.59.2)\n",
      "Requirement already satisfied: grpcio-status==1.59.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 40)) (1.59.2)\n",
      "Requirement already satisfied: h11==0.14.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 41)) (0.14.0)\n",
      "Requirement already satisfied: h2==4.1.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 42)) (4.1.0)\n",
      "Requirement already satisfied: hpack==4.0.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 43)) (4.0.0)\n",
      "Requirement already satisfied: httpcore==0.18.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 44)) (0.18.0)\n",
      "Requirement already satisfied: httpx==0.25.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 45)) (0.25.0)\n",
      "Requirement already satisfied: hyperframe==6.0.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 46)) (6.0.1)\n",
      "Requirement already satisfied: idna==3.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 47)) (3.4)\n",
      "Requirement already satisfied: ipykernel==6.21.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 48)) (6.21.3)\n",
      "Requirement already satisfied: ipython==8.11.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 49)) (8.11.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 50)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==8.0.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 51)) (8.0.4)\n",
      "Requirement already satisfied: isoduration==20.11.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 52)) (20.11.0)\n",
      "Requirement already satisfied: jedi==0.18.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 53)) (0.18.2)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 54)) (3.1.2)\n",
      "Requirement already satisfied: joblib==1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 55)) (1.2.0)\n",
      "Requirement already satisfied: json5==0.9.11 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 56)) (0.9.11)\n",
      "Requirement already satisfied: jsonpointer==2.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 57)) (2.3)\n",
      "Requirement already satisfied: jsonschema==4.17.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 58)) (4.17.3)\n",
      "Requirement already satisfied: jupyter==1.0.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 59)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-console==6.6.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 60)) (6.6.3)\n",
      "Requirement already satisfied: jupyter-events==0.6.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 61)) (0.6.3)\n",
      "Requirement already satisfied: jupyter-ydoc==0.2.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 62)) (0.2.2)\n",
      "Requirement already satisfied: jupyter_client==8.0.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 63)) (8.0.3)\n",
      "Requirement already satisfied: jupyter_core==5.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 64)) (5.2.0)\n",
      "Requirement already satisfied: jupyter_server==2.4.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 65)) (2.4.0)\n",
      "Requirement already satisfied: jupyter_server_fileid==0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 66)) (0.8.0)\n",
      "Requirement already satisfied: jupyter_server_terminals==0.4.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 67)) (0.4.4)\n",
      "Requirement already satisfied: jupyter_server_ydoc==0.6.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 68)) (0.6.1)\n",
      "Requirement already satisfied: jupyterlab==3.6.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 69)) (3.6.1)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.2.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 70)) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.5 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 71)) (3.0.5)\n",
      "Requirement already satisfied: jupyterlab_server==2.20.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 72)) (2.20.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 73)) (1.4.5)\n",
      "Requirement already satisfied: langdetect==1.0.9 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 74)) (1.0.9)\n",
      "Requirement already satisfied: lz4==4.3.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 75)) (4.3.2)\n",
      "Requirement already satisfied: MarkupSafe==2.1.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 76)) (2.1.2)\n",
      "Requirement already satisfied: matplotlib==3.8.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 77)) (3.8.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 78)) (0.1.6)\n",
      "Requirement already satisfied: mistune==2.0.5 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 79)) (2.0.5)\n",
      "Requirement already satisfied: nbclassic==0.5.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 80)) (0.5.3)\n",
      "Requirement already satisfied: nbclient==0.7.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 81)) (0.7.2)\n",
      "Requirement already satisfied: nbconvert==7.2.9 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 82)) (7.2.9)\n",
      "Requirement already satisfied: nbformat==5.7.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 83)) (5.7.3)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 84)) (1.5.6)\n",
      "Requirement already satisfied: notebook==6.5.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 85)) (6.5.3)\n",
      "Requirement already satisfied: notebook_shim==0.2.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 86)) (0.2.2)\n",
      "Requirement already satisfied: numpy==1.24.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 87)) (1.24.2)\n",
      "Requirement already satisfied: packaging==23.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 88)) (23.0)\n",
      "Requirement already satisfied: pandas==1.5.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 89)) (1.5.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 90)) (1.5.0)\n",
      "Requirement already satisfied: parso==0.8.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 91)) (0.8.3)\n",
      "Requirement already satisfied: patsy==0.5.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 92)) (0.5.3)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 93)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 94)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==10.0.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 95)) (10.0.1)\n",
      "Requirement already satisfied: platformdirs==3.1.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 96)) (3.1.0)\n",
      "Requirement already satisfied: prometheus-client==0.16.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 97)) (0.16.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.38 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 98)) (3.0.38)\n",
      "Requirement already satisfied: proto-plus==1.22.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 99)) (1.22.3)\n",
      "Requirement already satisfied: protobuf==4.24.4 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 100)) (4.24.4)\n",
      "Requirement already satisfied: psutil==5.9.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 101)) (5.9.4)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 102)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 103)) (0.2.2)\n",
      "Requirement already satisfied: pyasn1==0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 104)) (0.5.0)\n",
      "Requirement already satisfied: pyasn1-modules==0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 105)) (0.3.0)\n",
      "Requirement already satisfied: pycparser==2.21 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 106)) (2.21)\n",
      "Requirement already satisfied: pycryptodomex==3.19.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 107)) (3.19.0)\n",
      "Requirement already satisfied: Pygments==2.14.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 108)) (2.14.0)\n",
      "Requirement already satisfied: pyparsing==3.1.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 109)) (3.1.1)\n",
      "Requirement already satisfied: pyrsistent==0.19.3 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 110)) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 111)) (2.8.2)\n",
      "Requirement already satisfied: python-json-logger==2.0.7 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 112)) (2.0.7)\n",
      "Requirement already satisfied: pytz==2023.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 113)) (2023.3)\n",
      "Requirement already satisfied: PyYAML==6.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 114)) (6.0)\n",
      "Requirement already satisfied: pyzmq==25.0.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 115)) (25.0.0)\n",
      "Requirement already satisfied: qtconsole==5.4.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 116)) (5.4.0)\n",
      "Requirement already satisfied: QtPy==2.3.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 117)) (2.3.0)\n",
      "Requirement already satisfied: requests==2.28.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 118)) (2.28.2)\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 119)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 120)) (0.1.1)\n",
      "Requirement already satisfied: rsa==4.9 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 121)) (4.9)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 122)) (1.2.2)\n",
      "Requirement already satisfied: scipy==1.10.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 123)) (1.10.1)\n",
      "Requirement already satisfied: seaborn==0.13.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 124)) (0.13.0)\n",
      "Requirement already satisfied: Send2Trash==1.8.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 125)) (1.8.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 126)) (1.16.0)\n",
      "Requirement already satisfied: sklearn==0.0.post9 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 127)) (0.0.post9)\n",
      "Requirement already satisfied: sniffio==1.3.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 128)) (1.3.0)\n",
      "Requirement already satisfied: soupsieve==2.4 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 129)) (2.4)\n",
      "Requirement already satisfied: stack-data==0.6.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 130)) (0.6.2)\n",
      "Requirement already satisfied: statsmodels==0.14.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 131)) (0.14.0)\n",
      "Requirement already satisfied: terminado==0.17.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 132)) (0.17.1)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 133)) (3.1.0)\n",
      "Requirement already satisfied: tinycss2==1.2.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 134)) (1.2.1)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 135)) (2.0.1)\n",
      "Requirement already satisfied: tornado==6.2 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 136)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 137)) (4.66.1)\n",
      "Requirement already satisfied: traitlets==5.9.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 138)) (5.9.0)\n",
      "Requirement already satisfied: tzdata==2023.3 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 139)) (2023.3)\n",
      "Requirement already satisfied: uri-template==1.2.0 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 140)) (1.2.0)\n",
      "Requirement already satisfied: urllib3==2.0.5 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 141)) (2.0.5)\n",
      "Requirement already satisfied: utils==1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 142)) (1.0.1)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 143)) (0.2.6)\n",
      "Requirement already satisfied: webcolors==1.12 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 144)) (1.12)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 145)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.5.1 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 146)) (1.5.1)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.5 in /Users/rosy/Library/Python/3.10/lib/python/site-packages (from -r dependencies.txt (line 147)) (4.0.5)\n",
      "Requirement already satisfied: xgboost==2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 148)) (2.0.0)\n",
      "Requirement already satisfied: y-py==0.5.9 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 149)) (0.5.9)\n",
      "Requirement already satisfied: ypy-websocket==0.8.2 in /opt/homebrew/lib/python3.10/site-packages (from -r dependencies.txt (line 150)) (0.8.2)\n",
      "INFO: pip is looking at multiple versions of qtpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting QtPy==2.3.0\n",
      "  Using cached QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
      "INFO: pip is looking at multiple versions of qtconsole to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting qtconsole==5.4.0\n",
      "  Using cached qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
      "INFO: pip is looking at multiple versions of pyzmq to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyzmq==25.0.0\n",
      "  Using cached pyzmq-25.0.0-cp310-cp310-macosx_10_15_universal2.whl (1.8 MB)\n",
      "INFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyYAML==6.0\n",
      "  Using cached PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "INFO: pip is looking at multiple versions of pytz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytz==2023.3\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "INFO: pip is looking at multiple versions of python-json-logger to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-json-logger==2.0.7\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-dateutil==2.8.2\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "INFO: pip is looking at multiple versions of pyrsistent to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyrsistent==0.19.3\n",
      "  Using cached pyrsistent-0.19.3-cp310-cp310-macosx_10_9_universal2.whl (82 kB)\n",
      "INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyparsing==3.1.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "INFO: pip is looking at multiple versions of pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Pygments==2.14.0\n",
      "  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "INFO: pip is looking at multiple versions of pycryptodomex to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pycryptodomex==3.19.0\n",
      "  Using cached pycryptodomex-3.19.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "INFO: pip is looking at multiple versions of pycparser to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "INFO: pip is looking at multiple versions of pyasn1-modules to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyasn1-modules==0.3.0\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "INFO: pip is looking at multiple versions of pyasn1 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyasn1==0.5.0\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "INFO: pip is looking at multiple versions of pure-eval to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of ptyprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ptyprocess==0.7.0\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting psutil==5.9.4\n",
      "  Using cached psutil-5.9.4-cp38-abi3-macosx_11_0_arm64.whl (244 kB)\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf==4.24.4\n",
      "  Using cached protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "INFO: pip is looking at multiple versions of proto-plus to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting proto-plus==1.22.3\n",
      "  Using cached proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "INFO: pip is looking at multiple versions of prompt-toolkit to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting prompt-toolkit==3.0.38\n",
      "  Using cached prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "INFO: pip is looking at multiple versions of prometheus-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting prometheus-client==0.16.0\n",
      "  Using cached prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
      "INFO: pip is looking at multiple versions of platformdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting platformdirs==3.1.0\n",
      "  Using cached platformdirs-3.1.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of pillow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Pillow==10.0.1\n",
      "  Using cached Pillow-10.0.1-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "INFO: pip is looking at multiple versions of pickleshare to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pickleshare==0.7.5\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "INFO: pip is looking at multiple versions of pexpect to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pexpect==4.8.0\n",
      "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "INFO: pip is looking at multiple versions of patsy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting patsy==0.5.3\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "INFO: pip is looking at multiple versions of parso to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting parso==0.8.3\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "INFO: pip is looking at multiple versions of pandocfilters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandocfilters==1.5.0\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging==23.0\n",
      "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy==1.24.2\n",
      "  Using cached numpy-1.24.2-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "INFO: pip is looking at multiple versions of notebook-shim to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook_shim==0.2.2\n",
      "  Using cached notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook==6.5.3\n",
      "  Using cached notebook-6.5.3-py3-none-any.whl (529 kB)\n",
      "INFO: pip is looking at multiple versions of nest-asyncio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nest-asyncio==1.5.6\n",
      "  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of nbformat to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbformat==5.7.3\n",
      "  Using cached nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
      "INFO: pip is looking at multiple versions of nbconvert to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbconvert==7.2.9\n",
      "  Using cached nbconvert-7.2.9-py3-none-any.whl (274 kB)\n",
      "INFO: pip is looking at multiple versions of nbclient to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbclient==0.7.2\n",
      "  Using cached nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
      "INFO: pip is looking at multiple versions of nbclassic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nbclassic==0.5.3\n",
      "  Using cached nbclassic-0.5.3-py3-none-any.whl (10.0 MB)\n",
      "INFO: pip is looking at multiple versions of mistune to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mistune==2.0.5\n",
      "  Using cached mistune-2.0.5-py2.py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib-inline to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib-inline==0.1.6\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib==3.8.0\n",
      "  Using cached matplotlib-3.8.0-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting MarkupSafe==2.1.2\n",
      "  Using cached MarkupSafe-2.1.2-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "INFO: pip is looking at multiple versions of lz4 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting lz4==4.3.2\n",
      "  Using cached lz4-4.3.2-cp310-cp310-macosx_11_0_arm64.whl (212 kB)\n",
      "INFO: pip is looking at multiple versions of langdetect to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langdetect==1.0.9\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kiwisolver==1.4.5\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab-server to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab_server==2.20.0\n",
      "  Using cached jupyterlab_server-2.20.0-py3-none-any.whl (56 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab-widgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab-widgets==3.0.5\n",
      "  Using cached jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab-pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab-pygments==0.2.2\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyterlab==3.6.1\n",
      "  Using cached jupyterlab-3.6.1-py3-none-any.whl (8.9 MB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server-ydoc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server_ydoc==0.6.1\n",
      "  Using cached jupyter_server_ydoc-0.6.1-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server-terminals to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server_terminals==0.4.4\n",
      "  Using cached jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server-fileid to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server_fileid==0.8.0\n",
      "  Using cached jupyter_server_fileid-0.8.0-py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-server to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_server==2.4.0\n",
      "  Using cached jupyter_server-2.4.0-py3-none-any.whl (366 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_core==5.2.0\n",
      "  Using cached jupyter_core-5.2.0-py3-none-any.whl (94 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_client==8.0.3\n",
      "  Using cached jupyter_client-8.0.3-py3-none-any.whl (102 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-ydoc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-ydoc==0.2.2\n",
      "  Using cached jupyter_ydoc-0.2.2-py3-none-any.whl (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-events to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-events==0.6.3\n",
      "  Using cached jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-console to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-console==6.6.3\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter==1.0.0\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonschema==4.17.3\n",
      "  Using cached jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "INFO: pip is looking at multiple versions of jsonpointer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonpointer==2.3\n",
      "  Using cached jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "INFO: pip is looking at multiple versions of json5 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting json5==0.9.11\n",
      "  Using cached json5-0.9.11-py2.py3-none-any.whl (19 kB)\n",
      "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting joblib==1.2.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Jinja2==3.1.2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jedi==0.18.2\n",
      "  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of isoduration to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting isoduration==20.11.0\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipywidgets==8.0.4\n",
      "  Using cached ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
      "INFO: pip is looking at multiple versions of ipython-genutils to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython-genutils==0.2.0\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython==8.11.0\n",
      "  Using cached ipython-8.11.0-py3-none-any.whl (793 kB)\n",
      "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipykernel==6.21.3\n",
      "  Using cached ipykernel-6.21.3-py3-none-any.whl (149 kB)\n",
      "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting idna==3.4\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "INFO: pip is looking at multiple versions of hyperframe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting hyperframe==6.0.1\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "INFO: pip is looking at multiple versions of httpx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting httpx==0.25.0\n",
      "  Using cached httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "INFO: pip is looking at multiple versions of httpcore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting httpcore==0.18.0\n",
      "  Using cached httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "INFO: pip is looking at multiple versions of hpack to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting hpack==4.0.0\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "INFO: pip is looking at multiple versions of h2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h2==4.1.0\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "INFO: pip is looking at multiple versions of h11 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h11==0.14.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status==1.59.2\n",
      "  Using cached grpcio_status-1.59.2-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio==1.59.2\n",
      "  Using cached grpcio-1.59.2-cp310-cp310-macosx_12_0_universal2.whl (9.5 MB)\n",
      "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting googleapis-common-protos==1.61.0\n",
      "  Using cached googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-generativeai==0.2.2\n",
      "  Using cached google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of google-cloud-translate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-translate==3.12.1\n",
      "  Using cached google_cloud_translate-3.12.1-py2.py3-none-any.whl (128 kB)\n",
      "INFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-cloud-core==2.3.3\n",
      "  Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth==2.23.4\n",
      "  Using cached google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "INFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-api-core==2.12.0\n",
      "  Using cached google_api_core-2.12.0-py3-none-any.whl (121 kB)\n",
      "INFO: pip is looking at multiple versions of google-ai-generativelanguage to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-ai-generativelanguage==0.3.3\n",
      "  Using cached google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
      "INFO: pip is looking at multiple versions of fqdn to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fqdn==1.5.1\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fonttools==4.42.1\n",
      "  Using cached fonttools-4.42.1-cp310-cp310-macosx_10_9_universal2.whl (2.7 MB)\n",
      "INFO: pip is looking at multiple versions of fastjsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fastjsonschema==2.16.3\n",
      "  Using cached fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of executing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting executing==1.2.0\n",
      "  Using cached executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting defusedxml==0.7.1\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of deep-translator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting deep-translator==1.11.4\n",
      "  Using cached deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting decorator==5.1.1\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting debugpy==1.6.6\n",
      "  Using cached debugpy-1.6.6-py2.py3-none-any.whl (4.9 MB)\n",
      "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cycler==0.11.0\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy==1.1.1\n",
      "  Using cached contourpy-1.1.1-cp310-cp310-macosx_11_0_arm64.whl (232 kB)\n",
      "INFO: pip is looking at multiple versions of comm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting comm==0.1.2\n",
      "  Using cached comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
      "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting colorama==0.4.6\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting charset-normalizer==3.1.0\n",
      "  Using cached charset_normalizer-3.1.0-cp310-cp310-macosx_11_0_arm64.whl (123 kB)\n",
      "INFO: pip is looking at multiple versions of cffi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cffi==1.15.1\n",
      "  Using cached cffi-1.15.1-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting certifi==2022.12.7\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "INFO: pip is looking at multiple versions of cachetools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cachetools==5.3.2\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of browser-cookie3 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting browser-cookie3==0.19.1\n",
      "  Using cached browser_cookie3-0.19.1-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of bleach to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bleach==6.0.0\n",
      "  Using cached bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "INFO: pip is looking at multiple versions of beautifulsoup4 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting beautifulsoup4==4.11.2\n",
      "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "INFO: pip is looking at multiple versions of bardapi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bardapi==0.1.38\n",
      "  Using cached bardapi-0.1.38-py3-none-any.whl (39 kB)\n",
      "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting backcall==0.2.0\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of babel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Babel==2.12.1\n",
      "  Using cached Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
      "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting attrs==22.2.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "INFO: pip is looking at multiple versions of asttokens to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting asttokens==2.2.1\n",
      "  Using cached asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of arrow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting arrow==1.2.3\n",
      "  Using cached arrow-1.2.3-py3-none-any.whl (66 kB)\n",
      "INFO: pip is looking at multiple versions of argon2-cffi-bindings to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting argon2-cffi-bindings==21.2.0\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "INFO: pip is looking at multiple versions of argon2-cffi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting argon2-cffi==21.3.0\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of appnope to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting appnope==0.1.3\n",
      "  Using cached appnope-0.1.3-py2.py3-none-any.whl (4.4 kB)\n",
      "INFO: pip is looking at multiple versions of anyio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting anyio==3.6.2\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "INFO: pip is looking at multiple versions of aiosqlite to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiosqlite==0.18.0\n",
      "  Using cached aiosqlite-0.18.0-py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of aiofiles to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiofiles==22.1.0\n",
      "  Using cached aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
      "\u001b[31mERROR: Cannot install requests==2.28.2 and urllib3==2.0.5 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested urllib3==2.0.5\n",
      "    requests 2.28.2 depends on urllib3<1.27 and >=1.21.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r dependencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import scipy\n",
    "import importlib\n",
    "import helper, consts\n",
    "importlib.reload(consts)\n",
    "importlib.reload(helper)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tonight'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROW = consts.ROW\n",
    "COL = consts.COL\n",
    "RAW_DATA_PATH = consts.RAW_DATA_PATH\n",
    "RESPONSE_NAME = consts.RESPONSE_NAME\n",
    "\n",
    "RESPONSE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "does_sub_df_has_Nan = lambda df, col_name: df[[col_name]].isna().any(axis=COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local read\n",
    "\n",
    "# take in testing day - split into year and month \n",
    "\n",
    "#trainRange = helper.get_train_from_testday('20150102')\n",
    "#files = helper.get_file_names(trainRange[0],trainRange[1]) # get filenames from before 6/1/2015\n",
    "\n",
    "files = helper.get_file_names('20150101','20150601')\n",
    "dfs = [pd.read_csv(consts.DATA_PATH_2015 + f\"{f}\") for f in files]\n",
    "main_df = pd.concat(dfs)\n",
    "main_df.shape\n",
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150601_1200.csv\")\n",
    "x_cols = [\"rrirpnxm_nt_0\", \"rrirpnxm_lst15_0\",\"rrirpnxm_lsthrx15_0\", \"rrirpnxm_toxhr_0\"]\n",
    "saved_cols = x_cols + [RESPONSE_NAME]\n",
    "training_df = main_df[saved_cols]\n",
    "testing_df = test_df[saved_cols]\n",
    "\n",
    "# folder_path = '../data/training_data'\n",
    "# file_list = glob.glob(folder_path + \"/*.csv\") \n",
    "# main_df = pd.DataFrame(pd.read_csv(file_list[0])) \n",
    "# for i in range(1,len(file_list)): \n",
    "#     df = pd.read_csv(file_list[i]) \n",
    "#     # df = pd.DataFrame(data) \n",
    "#     main_df = pd.concat([main_df,df],axis=0) \n",
    "\n",
    "# df = pd.concat(map(pd.read_csv,glob.glob(folder_path + '/*.csv')))\n",
    "\n",
    "#data_20191202_1200_df = pd.read_csv(RAW_DATA_PATH + \"data_20191202_1200.csv\")\n",
    "#data_20191203_1200_df = pd.read_csv(RAW_DATA_PATH + \"data_20191203_1200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309918, 252)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting df\n",
    "\n",
    "data_20150602_1200_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150602_1200.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309918, 252)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3146, 252)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_20150602_1200_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191202:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 309918 entries, 0 to 3145\n",
      "Columns: 252 entries, eqid to tr_toxhr_0\n",
      "dtypes: float64(251), int64(1)\n",
      "memory usage: 598.2 MB\n",
      "Columns with NaN: Empty DataFrame\n",
      "Columns: [eqid, wt, today, tonight, tmwam, dn3sttmwmd, dn1, dn4x1, cftorrrelstd_open_0, liqlog_open_0, llirpnxm_am_1, llirpnxm_dy_12to16, llirpnxm_dy_17to21, llirpnxm_dy_1to3, llirpnxm_dy_4to6, llirpnxm_dy_7to11, llirpnxm_lst15_0, llirpnxm_lsthrx15_0, llirpnxm_md_1, llirpnxm_nt_0, llirpnxm_nt_1, llirpnxm_nt_12to16, llirpnxm_nt_17to21, llirpnxm_nt_1to3, llirpnxm_nt_4to6, llirpnxm_nt_7to11, llirpnxm_pm_1, llirpnxm_toxhr_0, mocrelvol_open_1, mocrelvol_open_13to17, mocrelvol_open_18to22, mocrelvol_open_2to4, mocrelvol_open_5to7, mocrelvol_open_8to12, momr10d_open_0, momr50dx10d_open_0, moorelvol_open_0, moorelvol_open_12to16, moorelvol_open_17to21, moorelvol_open_1to3, moorelvol_open_4to6, moorelvol_open_7to11, nnetticksrelmultstdev_am_1, nnetticksrelmultstdev_dy_12to16, nnetticksrelmultstdev_dy_17to21, nnetticksrelmultstdev_dy_1to3, nnetticksrelmultstdev_dy_4to6, nnetticksrelmultstdev_dy_7to11, nnetticksrelmultstdev_lst15_0, nnetticksrelmultstdev_lsthrx15_0, nnetticksrelmultstdev_md_1, nnetticksrelmultstdev_nt_0, nnetticksrelmultstdev_nt_1, nnetticksrelmultstdev_nt_12to16, nnetticksrelmultstdev_nt_17to21, nnetticksrelmultstdev_nt_1to3, nnetticksrelmultstdev_nt_4to6, nnetticksrelmultstdev_nt_7to11, nnetticksrelmultstdev_pm_1, nnetticksrelmultstdev_toxhr_0, nnetticksrelrrsign_am_1, nnetticksrelrrsign_dy_12to16, nnetticksrelrrsign_dy_17to21, nnetticksrelrrsign_dy_1to3, nnetticksrelrrsign_dy_4to6, nnetticksrelrrsign_dy_7to11, nnetticksrelrrsign_lst15_0, nnetticksrelrrsign_lsthrx15_0, nnetticksrelrrsign_md_1, nnetticksrelrrsign_nt_0, nnetticksrelrrsign_nt_1, nnetticksrelrrsign_nt_12to16, nnetticksrelrrsign_nt_17to21, nnetticksrelrrsign_nt_1to3, nnetticksrelrrsign_nt_4to6, nnetticksrelrrsign_nt_7to11, nnetticksrelrrsign_pm_1, nnetticksrelrrsign_toxhr_0, nsameticksrelmultstdev_am_1, nsameticksrelmultstdev_dy_12to16, nsameticksrelmultstdev_dy_17to21, nsameticksrelmultstdev_dy_1to3, nsameticksrelmultstdev_dy_4to6, nsameticksrelmultstdev_dy_7to11, nsameticksrelmultstdev_lst15_0, nsameticksrelmultstdev_lsthrx15_0, nsameticksrelmultstdev_md_1, nsameticksrelmultstdev_nt_0, nsameticksrelmultstdev_nt_1, nsameticksrelmultstdev_nt_12to16, nsameticksrelmultstdev_nt_17to21, nsameticksrelmultstdev_nt_1to3, nsameticksrelmultstdev_nt_4to6, nsameticksrelmultstdev_nt_7to11, nsameticksrelmultstdev_pm_1, nsameticksrelmultstdev_toxhr_0, nsameticksrelrrsign_am_1, nsameticksrelrrsign_dy_12to16, nsameticksrelrrsign_dy_17to21, nsameticksrelrrsign_dy_1to3, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 252 columns]\n",
      "\n",
      "20191203:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3146 entries, 0 to 3145\n",
      "Columns: 252 entries, eqid to tr_toxhr_0\n",
      "dtypes: float64(251), int64(1)\n",
      "memory usage: 6.0 MB\n",
      "Columns with NaN: Empty DataFrame\n",
      "Columns: [eqid, wt, today, tonight, tmwam, dn3sttmwmd, dn1, dn4x1, cftorrrelstd_open_0, liqlog_open_0, llirpnxm_am_1, llirpnxm_dy_12to16, llirpnxm_dy_17to21, llirpnxm_dy_1to3, llirpnxm_dy_4to6, llirpnxm_dy_7to11, llirpnxm_lst15_0, llirpnxm_lsthrx15_0, llirpnxm_md_1, llirpnxm_nt_0, llirpnxm_nt_1, llirpnxm_nt_12to16, llirpnxm_nt_17to21, llirpnxm_nt_1to3, llirpnxm_nt_4to6, llirpnxm_nt_7to11, llirpnxm_pm_1, llirpnxm_toxhr_0, mocrelvol_open_1, mocrelvol_open_13to17, mocrelvol_open_18to22, mocrelvol_open_2to4, mocrelvol_open_5to7, mocrelvol_open_8to12, momr10d_open_0, momr50dx10d_open_0, moorelvol_open_0, moorelvol_open_12to16, moorelvol_open_17to21, moorelvol_open_1to3, moorelvol_open_4to6, moorelvol_open_7to11, nnetticksrelmultstdev_am_1, nnetticksrelmultstdev_dy_12to16, nnetticksrelmultstdev_dy_17to21, nnetticksrelmultstdev_dy_1to3, nnetticksrelmultstdev_dy_4to6, nnetticksrelmultstdev_dy_7to11, nnetticksrelmultstdev_lst15_0, nnetticksrelmultstdev_lsthrx15_0, nnetticksrelmultstdev_md_1, nnetticksrelmultstdev_nt_0, nnetticksrelmultstdev_nt_1, nnetticksrelmultstdev_nt_12to16, nnetticksrelmultstdev_nt_17to21, nnetticksrelmultstdev_nt_1to3, nnetticksrelmultstdev_nt_4to6, nnetticksrelmultstdev_nt_7to11, nnetticksrelmultstdev_pm_1, nnetticksrelmultstdev_toxhr_0, nnetticksrelrrsign_am_1, nnetticksrelrrsign_dy_12to16, nnetticksrelrrsign_dy_17to21, nnetticksrelrrsign_dy_1to3, nnetticksrelrrsign_dy_4to6, nnetticksrelrrsign_dy_7to11, nnetticksrelrrsign_lst15_0, nnetticksrelrrsign_lsthrx15_0, nnetticksrelrrsign_md_1, nnetticksrelrrsign_nt_0, nnetticksrelrrsign_nt_1, nnetticksrelrrsign_nt_12to16, nnetticksrelrrsign_nt_17to21, nnetticksrelrrsign_nt_1to3, nnetticksrelrrsign_nt_4to6, nnetticksrelrrsign_nt_7to11, nnetticksrelrrsign_pm_1, nnetticksrelrrsign_toxhr_0, nsameticksrelmultstdev_am_1, nsameticksrelmultstdev_dy_12to16, nsameticksrelmultstdev_dy_17to21, nsameticksrelmultstdev_dy_1to3, nsameticksrelmultstdev_dy_4to6, nsameticksrelmultstdev_dy_7to11, nsameticksrelmultstdev_lst15_0, nsameticksrelmultstdev_lsthrx15_0, nsameticksrelmultstdev_md_1, nsameticksrelmultstdev_nt_0, nsameticksrelmultstdev_nt_1, nsameticksrelmultstdev_nt_12to16, nsameticksrelmultstdev_nt_17to21, nsameticksrelmultstdev_nt_1to3, nsameticksrelmultstdev_nt_4to6, nsameticksrelmultstdev_nt_7to11, nsameticksrelmultstdev_pm_1, nsameticksrelmultstdev_toxhr_0, nsameticksrelrrsign_am_1, nsameticksrelrrsign_dy_12to16, nsameticksrelrrsign_dy_17to21, nsameticksrelrrsign_dy_1to3, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 252 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"20191202:\")\n",
    "main_df.info()\n",
    "print(f\"Columns with NaN: {main_df[main_df.isna().any(axis=COL)]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"20191203:\")\n",
    "data_20150602_1200_df.info()\n",
    "print(f\"Columns with NaN: {data_20150602_1200_df[data_20150602_1200_df.isna().any(axis=COL)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191202 - unique eqid count: 3374\n",
      "20191203 - unique eqid count: 3146\n"
     ]
    }
   ],
   "source": [
    "print(f\"20191202 - unique eqid count: {main_df.eqid.nunique()}\")\n",
    "print(f\"20191203 - unique eqid count: {data_20150602_1200_df.eqid.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.drop('eqid', axis=COL, inplace=True)\n",
    "data_20150602_1200_df.drop('eqid', axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>tmwam</th>\n",
       "      <th>dn3sttmwmd</th>\n",
       "      <th>dn1</th>\n",
       "      <th>dn4x1</th>\n",
       "      <th>cftorrrelstd_open_0</th>\n",
       "      <th>liqlog_open_0</th>\n",
       "      <th>llirpnxm_am_1</th>\n",
       "      <th>...</th>\n",
       "      <th>tr_md_1</th>\n",
       "      <th>tr_nt_0</th>\n",
       "      <th>tr_nt_1</th>\n",
       "      <th>tr_nt_12to16</th>\n",
       "      <th>tr_nt_17to21</th>\n",
       "      <th>tr_nt_1to3</th>\n",
       "      <th>tr_nt_4to6</th>\n",
       "      <th>tr_nt_7to11</th>\n",
       "      <th>tr_pm_1</th>\n",
       "      <th>tr_toxhr_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.093743</td>\n",
       "      <td>-0.118355</td>\n",
       "      <td>-0.082232</td>\n",
       "      <td>-0.406343</td>\n",
       "      <td>-0.217713</td>\n",
       "      <td>-0.413634</td>\n",
       "      <td>-2.029335</td>\n",
       "      <td>-3.422019</td>\n",
       "      <td>-0.030027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181246</td>\n",
       "      <td>-0.248395</td>\n",
       "      <td>-0.248395</td>\n",
       "      <td>-0.262104</td>\n",
       "      <td>-0.262104</td>\n",
       "      <td>-0.248395</td>\n",
       "      <td>-0.248395</td>\n",
       "      <td>-0.262104</td>\n",
       "      <td>-0.160350</td>\n",
       "      <td>-0.198276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.102819</td>\n",
       "      <td>0.151392</td>\n",
       "      <td>0.092196</td>\n",
       "      <td>0.325323</td>\n",
       "      <td>0.215648</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>2.498018</td>\n",
       "      <td>1.810317</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249656</td>\n",
       "      <td>0.364367</td>\n",
       "      <td>0.364367</td>\n",
       "      <td>0.527026</td>\n",
       "      <td>0.527026</td>\n",
       "      <td>0.511446</td>\n",
       "      <td>0.511446</td>\n",
       "      <td>0.527026</td>\n",
       "      <td>0.289527</td>\n",
       "      <td>0.236002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wt     today   tonight     tmwam  dn3sttmwmd       dn1     dn4x1  \\\n",
       "min  0.000015 -0.093743 -0.118355 -0.082232   -0.406343 -0.217713 -0.413634   \n",
       "max  0.003904  0.102819  0.151392  0.092196    0.325323  0.215648  0.331000   \n",
       "\n",
       "     cftorrrelstd_open_0  liqlog_open_0  llirpnxm_am_1  ...   tr_md_1  \\\n",
       "min            -2.029335      -3.422019      -0.030027  ... -0.181246   \n",
       "max             2.498018       1.810317       0.031884  ...  0.249656   \n",
       "\n",
       "      tr_nt_0   tr_nt_1  tr_nt_12to16  tr_nt_17to21  tr_nt_1to3  tr_nt_4to6  \\\n",
       "min -0.248395 -0.248395     -0.262104     -0.262104   -0.248395   -0.248395   \n",
       "max  0.364367  0.364367      0.527026      0.527026    0.511446    0.511446   \n",
       "\n",
       "     tr_nt_7to11   tr_pm_1  tr_toxhr_0  \n",
       "min    -0.262104 -0.160350   -0.198276  \n",
       "max     0.527026  0.289527    0.236002  \n",
       "\n",
       "[2 rows x 251 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"training set:\")\n",
    "main_df.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150602:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wt</th>\n",
       "      <th>today</th>\n",
       "      <th>tonight</th>\n",
       "      <th>tmwam</th>\n",
       "      <th>dn3sttmwmd</th>\n",
       "      <th>dn1</th>\n",
       "      <th>dn4x1</th>\n",
       "      <th>cftorrrelstd_open_0</th>\n",
       "      <th>liqlog_open_0</th>\n",
       "      <th>llirpnxm_am_1</th>\n",
       "      <th>...</th>\n",
       "      <th>tr_md_1</th>\n",
       "      <th>tr_nt_0</th>\n",
       "      <th>tr_nt_1</th>\n",
       "      <th>tr_nt_12to16</th>\n",
       "      <th>tr_nt_17to21</th>\n",
       "      <th>tr_nt_1to3</th>\n",
       "      <th>tr_nt_4to6</th>\n",
       "      <th>tr_nt_7to11</th>\n",
       "      <th>tr_pm_1</th>\n",
       "      <th>tr_toxhr_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.045065</td>\n",
       "      <td>-0.052672</td>\n",
       "      <td>-0.042489</td>\n",
       "      <td>-0.203398</td>\n",
       "      <td>-0.099692</td>\n",
       "      <td>-0.2117</td>\n",
       "      <td>-1.606556</td>\n",
       "      <td>-3.331233</td>\n",
       "      <td>-0.007814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064435</td>\n",
       "      <td>-0.072432</td>\n",
       "      <td>-0.218679</td>\n",
       "      <td>-0.242618</td>\n",
       "      <td>-0.236863</td>\n",
       "      <td>-0.218679</td>\n",
       "      <td>-0.185715</td>\n",
       "      <td>-0.151686</td>\n",
       "      <td>-0.023336</td>\n",
       "      <td>-0.079471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0.066898</td>\n",
       "      <td>0.069924</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.164918</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>2.501099</td>\n",
       "      <td>1.580095</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120576</td>\n",
       "      <td>0.053742</td>\n",
       "      <td>0.277050</td>\n",
       "      <td>0.235876</td>\n",
       "      <td>0.267265</td>\n",
       "      <td>0.532310</td>\n",
       "      <td>0.176683</td>\n",
       "      <td>0.364367</td>\n",
       "      <td>0.073329</td>\n",
       "      <td>0.077337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wt     today   tonight     tmwam  dn3sttmwmd       dn1   dn4x1  \\\n",
       "min  0.000016 -0.045065 -0.052672 -0.042489   -0.203398 -0.099692 -0.2117   \n",
       "max  0.001342  0.057321  0.066898  0.069924    0.223958  0.164918  0.2377   \n",
       "\n",
       "     cftorrrelstd_open_0  liqlog_open_0  llirpnxm_am_1  ...   tr_md_1  \\\n",
       "min            -1.606556      -3.331233      -0.007814  ... -0.064435   \n",
       "max             2.501099       1.580095       0.012865  ...  0.120576   \n",
       "\n",
       "      tr_nt_0   tr_nt_1  tr_nt_12to16  tr_nt_17to21  tr_nt_1to3  tr_nt_4to6  \\\n",
       "min -0.072432 -0.218679     -0.242618     -0.236863   -0.218679   -0.185715   \n",
       "max  0.053742  0.277050      0.235876      0.267265    0.532310    0.176683   \n",
       "\n",
       "     tr_nt_7to11   tr_pm_1  tr_toxhr_0  \n",
       "min    -0.151686 -0.023336   -0.079471  \n",
       "max     0.364367  0.073329    0.077337  \n",
       "\n",
       "[2 rows x 251 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"20150602:\")\n",
    "data_20150602_1200_df.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tonight'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESPONSE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the responses columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_responses = main_df[RESPONSE_NAME]\n",
    "testing_responses = data_20150602_1200_df[RESPONSE_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20191202_1200 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.drop(RESPONSE_NAME, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wt             7\n",
       "today          7\n",
       "tmwam          7\n",
       "dn3sttmwmd     7\n",
       "dn1            7\n",
       "              ..\n",
       "tr_nt_1to3     7\n",
       "tr_nt_4to6     7\n",
       "tr_nt_7to11    7\n",
       "tr_pm_1        7\n",
       "tr_toxhr_0     7\n",
       "Length: 250, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.corr().isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some column pairs have NaN correlations, meaning either or both columns have constant values in all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rvdelta_nt_0', 'rvdelta_nt_1', 'rvdelta_nt_12to16',\n",
       "       'rvdelta_nt_17to21', 'rvdelta_nt_1to3', 'rvdelta_nt_4to6',\n",
       "       'rvdelta_nt_7to11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columns where all rows have the same value\n",
    "constVal_columns = main_df.columns[main_df.apply(lambda x: x.nunique() == 1)]\n",
    "constVal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191202_1200_COLUMNS = list(constVal_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20191203_1200 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20150602_1200_df.drop(RESPONSE_NAME, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wt             7\n",
       "today          7\n",
       "tmwam          7\n",
       "dn3sttmwmd     7\n",
       "dn1            7\n",
       "              ..\n",
       "tr_nt_1to3     7\n",
       "tr_nt_4to6     7\n",
       "tr_nt_7to11    7\n",
       "tr_pm_1        7\n",
       "tr_toxhr_0     7\n",
       "Length: 250, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_20150602_1200_df.corr().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rvdelta_nt_0', 'rvdelta_nt_1', 'rvdelta_nt_12to16',\n",
       "       'rvdelta_nt_17to21', 'rvdelta_nt_1to3', 'rvdelta_nt_4to6',\n",
       "       'rvdelta_nt_7to11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get columns where all rows have the same value\n",
    "constVal_columns = data_20150602_1200_df.columns[data_20150602_1200_df.apply(lambda x: x.nunique() == 1)]\n",
    "constVal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191203_1200_COLUMNS = list(constVal_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get training_predictors_df and testing_predictors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191202_1200_COLUMNS_set = set(TOBE_REMOVED_20191202_1200_COLUMNS)\n",
    "TOBE_REMOVED_20191203_1200_COLUMNS_set = set(TOBE_REMOVED_20191203_1200_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Appear in TOBE_REMOVED_20191202_1200_COLUMNS_set but not in TOBE_REMOVED_20191203_1200_COLUMNS_set\n",
    "print(TOBE_REMOVED_20191202_1200_COLUMNS_set - TOBE_REMOVED_20191203_1200_COLUMNS_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Appear in TOBE_REMOVED_20191203_1200_COLUMNS_set but not in TOBE_REMOVED_20191202_1200_COLUMNS_set\n",
    "print(TOBE_REMOVED_20191203_1200_COLUMNS_set - TOBE_REMOVED_20191202_1200_COLUMNS_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m remove_20191202_stay_20191203_columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(TOBE_REMOVED_20191202_1200_COLUMNS_set \u001b[39m-\u001b[39m TOBE_REMOVED_20191203_1200_COLUMNS_set)\n\u001b[0;32m----> 2\u001b[0m data_20150602_1200_df[remove_20191202_stay_20191203_columns]\u001b[39m.\u001b[39;49mdescribe()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:10940\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[0;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[1;32m  10691\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m  10692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescribe\u001b[39m(\n\u001b[1;32m  10693\u001b[0m     \u001b[39mself\u001b[39m: NDFrameT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10697\u001b[0m     datetime_is_numeric: bool_t \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m  10698\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m  10699\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  10700\u001b[0m \u001b[39m    Generate descriptive statistics.\u001b[39;00m\n\u001b[1;32m  10701\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10938\u001b[0m \u001b[39m    max            NaN      3.0\u001b[39;00m\n\u001b[1;32m  10939\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 10940\u001b[0m     \u001b[39mreturn\u001b[39;00m describe_ndframe(\n\u001b[1;32m  10941\u001b[0m         obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m  10942\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m  10943\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m  10944\u001b[0m         datetime_is_numeric\u001b[39m=\u001b[39;49mdatetime_is_numeric,\n\u001b[1;32m  10945\u001b[0m         percentiles\u001b[39m=\u001b[39;49mpercentiles,\n\u001b[1;32m  10946\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/describe.py:94\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[0;34m(obj, include, exclude, datetime_is_numeric, percentiles)\u001b[0m\n\u001b[1;32m     89\u001b[0m     describer \u001b[39m=\u001b[39m SeriesDescriber(\n\u001b[1;32m     90\u001b[0m         obj\u001b[39m=\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mSeries\u001b[39m\u001b[39m\"\u001b[39m, obj),\n\u001b[1;32m     91\u001b[0m         datetime_is_numeric\u001b[39m=\u001b[39mdatetime_is_numeric,\n\u001b[1;32m     92\u001b[0m     )\n\u001b[1;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     describer \u001b[39m=\u001b[39m DataFrameDescriber(\n\u001b[1;32m     95\u001b[0m         obj\u001b[39m=\u001b[39;49mcast(\u001b[39m\"\u001b[39;49m\u001b[39mDataFrame\u001b[39;49m\u001b[39m\"\u001b[39;49m, obj),\n\u001b[1;32m     96\u001b[0m         include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m     97\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     98\u001b[0m         datetime_is_numeric\u001b[39m=\u001b[39;49mdatetime_is_numeric,\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m result \u001b[39m=\u001b[39m describer\u001b[39m.\u001b[39mdescribe(percentiles\u001b[39m=\u001b[39mpercentiles)\n\u001b[1;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/describe.py:171\u001b[0m, in \u001b[0;36mDataFrameDescriber.__init__\u001b[0;34m(self, obj, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexclude \u001b[39m=\u001b[39m exclude\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot describe a DataFrame without columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(obj, datetime_is_numeric\u001b[39m=\u001b[39mdatetime_is_numeric)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "remove_20191202_stay_20191203_columns = list(TOBE_REMOVED_20191202_1200_COLUMNS_set - TOBE_REMOVED_20191203_1200_COLUMNS_set)\n",
    "data_20150602_1200_df[remove_20191202_stay_20191203_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_COLUMNS = TOBE_REMOVED_20191202_1200_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are variances among those columns, I don't think removing them now benefits the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TOBE_REMOVED_COLUMNS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_20191202_1200_working_df \u001b[39m=\u001b[39m main_df\u001b[39m.\u001b[39mdrop(TOBE_REMOVED_COLUMNS, axis\u001b[39m=\u001b[39mCOL)\n\u001b[1;32m      2\u001b[0m data_20191203_1200_working_df \u001b[39m=\u001b[39m data_20150602_1200_df\u001b[39m.\u001b[39mdrop(TOBE_REMOVED_COLUMNS, axis\u001b[39m=\u001b[39mCOL)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TOBE_REMOVED_COLUMNS' is not defined"
     ]
    }
   ],
   "source": [
    "data_20191202_1200_working_df = main_df.drop(TOBE_REMOVED_COLUMNS, axis=COL)\n",
    "data_20191203_1200_working_df = data_20150602_1200_df.drop(TOBE_REMOVED_COLUMNS, axis=COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'rrirpnxm_nt_0' in main_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rosy: we will not remove the columns right now from above, instead, we will just select the predictor columns we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_working_df =  main_df[['rrirpnxm_nt_0','rrirpnxm_lst15_0','rrirpnxm_toxhr_0','rrirpnxm_lsthrx15_0']].copy()\n",
    "testing_working_df = data_20150602_1200_df[['rrirpnxm_nt_0','rrirpnxm_lst15_0','rrirpnxm_toxhr_0','rrirpnxm_lsthrx15_0']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% negative correlations ranking: [-0.025984035108515352, -0.04010837969125543, -0.04451972163578744, -0.057638337420823915]\n",
      "99% negative correlations ranking: [0.700494493689765, 0.700494493689765, 0.7001372889622377, 0.6969260714691754]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rrirpnxm_nt_0</th>\n",
       "      <th>rrirpnxm_lst15_0</th>\n",
       "      <th>rrirpnxm_toxhr_0</th>\n",
       "      <th>rrirpnxm_lsthrx15_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.234578</td>\n",
       "      <td>0.239668</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.231114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.511197</td>\n",
       "      <td>0.507088</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.512929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.063796</td>\n",
       "      <td>-0.032729</td>\n",
       "      <td>-0.063796</td>\n",
       "      <td>-0.043271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.015606</td>\n",
       "      <td>-0.015867</td>\n",
       "      <td>-0.048402</td>\n",
       "      <td>-0.035364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>-0.026759</td>\n",
       "      <td>-0.016136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.251236</td>\n",
       "      <td>0.251236</td>\n",
       "      <td>0.242315</td>\n",
       "      <td>0.250343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rrirpnxm_nt_0  rrirpnxm_lst15_0  rrirpnxm_toxhr_0  rrirpnxm_lsthrx15_0\n",
       "count       4.000000          4.000000          4.000000             4.000000\n",
       "mean        0.234578          0.239668          0.220672             0.231114\n",
       "std         0.511197          0.507088          0.520020             0.512929\n",
       "min        -0.063796         -0.032729         -0.063796            -0.043271\n",
       "25%        -0.015606         -0.015867         -0.048402            -0.035364\n",
       "50%         0.001053         -0.004299         -0.026759            -0.016136\n",
       "75%         0.251236          0.251236          0.242315             0.250343\n",
       "max         1.000000          1.000000          1.000000             1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"1% negative correlations ranking: {sorted(trainig_working_df.corr().quantile(0.1), reverse=True)}\")\n",
    "print(f\"99% negative correlations ranking: {sorted(trainig_working_df.corr().quantile(0.9), reverse=True)}\")\n",
    "trainig_working_df.corr().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_20191202_1200_working_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Box to do figure out which columns to use\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m training_predictors_df \u001b[39m=\u001b[39m data_20191202_1200_working_df\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m testing_predictors_df \u001b[39m=\u001b[39m data_20191203_1200_working_df\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_20191202_1200_working_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Box to do figure out which columns to use\n",
    "training_predictors_df = data_20191202_1200_working_df.copy()\n",
    "testing_predictors_df = data_20191203_1200_working_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(training_predictors_df.quantile(0.25) / training_predictors_df.quantile(0.01), reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(training_predictors_df.quantile(0.99) / training_predictors_df.quantile(0.75), reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(training_responses, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect influential points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use Mahalanobis distance, which computes distances from the data's centre and create an oval boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.mean(training_predictors_df, axis=0)\n",
    "cov_matrix = np.cov(training_predictors_df, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_distances = []\n",
    "for index, row in training_predictors_df.iterrows():\n",
    "    mahalanobis_distance = scipy.spatial.distance.mahalanobis(row, mean_vector, inv_cov_matrix)\n",
    "    mahalanobis_distances.append(mahalanobis_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df['mahalanobis_dist'] = mahalanobis_distances\n",
    "training_predictors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Need discussion\n",
    "mahal_threshold = 3 # Typical 'mahal_threshold' is 3\n",
    "outlier_significance_val = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df['mahal_p_value'] = 1 - scipy.stats.chi2.cdf(training_predictors_df['mahalanobis_dist'], mahal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_condition = (training_predictors_df['mahal_p_value'] < outlier_significance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonOutlier_indices = training_predictors_df[~outlier_condition].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_col = 'response'\n",
    "training_predictors_df[temp_col] = training_responses\n",
    "\n",
    "training_predictors_df = training_predictors_df[~outlier_condition]\n",
    "\n",
    "training_responses = training_predictors_df[temp_col]\n",
    "training_predictors_df.drop(temp_col, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df.drop(['mahalanobis_dist', 'mahal_p_value'], axis = COL, inplace=True)\n",
    "training_predictors_df.reset_index(drop=True)\n",
    "training_predictors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge features and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([training_predictors_df, pd.DataFrame({consts.RESPONSE_NAME: training_responses})], \n",
    "                     axis=COL)\n",
    "test_df = pd.concat([testing_predictors_df, pd.DataFrame({consts.RESPONSE_NAME: testing_responses})], \n",
    "                    axis=COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '../data/cleaned_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train_filename = 'training_data.csv'\n",
    "out_test_filename = 'testing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(out_path + out_train_filename, index=False)\n",
    "test_df.to_csv(out_path + out_test_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > dependencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = helper.get_file_names('20150601') # get filenames from before 6/1/2015\n",
    "dfs = [pd.read_csv(consts.DATA_PATH_2015 + f\"/{f}\") for f in files]\n",
    "main_df = pd.concat(dfs)\n",
    "main_df.shape\n",
    "\n",
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"/data.20150601_1200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"/data.20150601_1200\")\n",
    "x_cols = [\"rrirpnxm_nt_0\", \"rrirpnxm_lst15_0\",\"rrirpnxm_lsthrx15_0\", \"rrirpnxm_toxhr_0\"]\n",
    "saved_cols = x_cols + [RESPONSE_NAME]\n",
    "training_df = main_df[saved_cols]\n",
    "testing_df = test_df[saved_cols]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
