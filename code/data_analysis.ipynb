{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Hoang Chu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r dependencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import scipy\n",
    "import importlib\n",
    "import helper, consts\n",
    "importlib.reload(consts)\n",
    "importlib.reload(helper)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tonight'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROW = consts.ROW\n",
    "COL = consts.COL\n",
    "RAW_DATA_PATH = consts.RAW_DATA_PATH\n",
    "RESPONSE_NAME = consts.RESPONSE_NAME\n",
    "\n",
    "RESPONSE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "does_sub_df_has_Nan = lambda df, col_name: df[[col_name]].isna().any(axis=COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRange = helper.get_train_from_testday('20150102')\n",
    "files = helper.get_file_names(trainRange[0],trainRange[1]) # get filenames from before 6/1/2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local read\n",
    "\n",
    "# take in testing day - split into year and month \n",
    "\n",
    "\n",
    "\n",
    "files = helper.get_file_names('20150101','20150601')\n",
    "dfs = [pd.read_csv(consts.DATA_PATH_2015 + f\"{f}\") for f in files]\n",
    "main_df = pd.concat(dfs)\n",
    "main_df.shape\n",
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150601_1200.csv\")\n",
    "x_cols = [\"rrirpnxm_nt_0\", \"rrirpnxm_lst15_0\",\"rrirpnxm_lsthrx15_0\", \"rrirpnxm_toxhr_0\"]\n",
    "saved_cols = x_cols + [RESPONSE_NAME]\n",
    "training_df = main_df[saved_cols]\n",
    "testing_df = test_df[saved_cols]\n",
    "\n",
    "# folder_path = '../data/training_data'\n",
    "# file_list = glob.glob(folder_path + \"/*.csv\") \n",
    "# main_df = pd.DataFrame(pd.read_csv(file_list[0])) \n",
    "# for i in range(1,len(file_list)): \n",
    "#     df = pd.read_csv(file_list[i]) \n",
    "#     # df = pd.DataFrame(data) \n",
    "#     main_df = pd.concat([main_df,df],axis=0) \n",
    "\n",
    "# df = pd.concat(map(pd.read_csv,glob.glob(folder_path + '/*.csv')))\n",
    "\n",
    "#data_20191202_1200_df = pd.read_csv(RAW_DATA_PATH + \"data_20191202_1200.csv\")\n",
    "#data_20191203_1200_df = pd.read_csv(RAW_DATA_PATH + \"data_20191203_1200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting df\n",
    "\n",
    "data_20150602_1200_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150602_1200.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20150602_1200_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"20191202:\")\n",
    "main_df.info()\n",
    "print(f\"Columns with NaN: {main_df[main_df.isna().any(axis=COL)]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"20191203:\")\n",
    "data_20150602_1200_df.info()\n",
    "print(f\"Columns with NaN: {data_20150602_1200_df[data_20150602_1200_df.isna().any(axis=COL)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"20191202 - unique eqid count: {main_df.eqid.nunique()}\")\n",
    "print(f\"20191203 - unique eqid count: {data_20150602_1200_df.eqid.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.drop('eqid', axis=COL, inplace=True)\n",
    "data_20150602_1200_df.drop('eqid', axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training set:\")\n",
    "main_df.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"20150602:\")\n",
    "data_20150602_1200_df.describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the responses columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_responses = main_df[RESPONSE_NAME]\n",
    "testing_responses = data_20150602_1200_df[RESPONSE_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20191202_1200 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.drop(RESPONSE_NAME, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.corr().isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some column pairs have NaN correlations, meaning either or both columns have constant values in all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns where all rows have the same value\n",
    "constVal_columns = main_df.columns[main_df.apply(lambda x: x.nunique() == 1)]\n",
    "constVal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191202_1200_COLUMNS = list(constVal_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20191203_1200 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20150602_1200_df.drop(RESPONSE_NAME, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20150602_1200_df.corr().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns where all rows have the same value\n",
    "constVal_columns = data_20150602_1200_df.columns[data_20150602_1200_df.apply(lambda x: x.nunique() == 1)]\n",
    "constVal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191203_1200_COLUMNS = list(constVal_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get training_predictors_df and testing_predictors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_20191202_1200_COLUMNS_set = set(TOBE_REMOVED_20191202_1200_COLUMNS)\n",
    "TOBE_REMOVED_20191203_1200_COLUMNS_set = set(TOBE_REMOVED_20191203_1200_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appear in TOBE_REMOVED_20191202_1200_COLUMNS_set but not in TOBE_REMOVED_20191203_1200_COLUMNS_set\n",
    "print(TOBE_REMOVED_20191202_1200_COLUMNS_set - TOBE_REMOVED_20191203_1200_COLUMNS_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appear in TOBE_REMOVED_20191203_1200_COLUMNS_set but not in TOBE_REMOVED_20191202_1200_COLUMNS_set\n",
    "print(TOBE_REMOVED_20191203_1200_COLUMNS_set - TOBE_REMOVED_20191202_1200_COLUMNS_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_20191202_stay_20191203_columns = list(TOBE_REMOVED_20191202_1200_COLUMNS_set - TOBE_REMOVED_20191203_1200_COLUMNS_set)\n",
    "remove_20191202_stay_20191203_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_20150602_1200_df[remove_20191202_stay_20191203_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOBE_REMOVED_COLUMNS = TOBE_REMOVED_20191202_1200_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are variances among those columns, I don't think removing them now benefits the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20191202_1200_working_df = main_df.drop(TOBE_REMOVED_COLUMNS, axis=COL)\n",
    "data_20191203_1200_working_df = data_20150602_1200_df.drop(TOBE_REMOVED_COLUMNS, axis=COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'rrirpnxm_nt_0' in main_df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rosy: we will not remove the columns right now from above, instead, we will just select the predictor columns we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig_working_df =  main_df[['rrirpnxm_nt_0','rrirpnxm_lst15_0','rrirpnxm_toxhr_0','rrirpnxm_lsthrx15_0']].copy()\n",
    "testing_working_df = data_20150602_1200_df[['rrirpnxm_nt_0','rrirpnxm_lst15_0','rrirpnxm_toxhr_0','rrirpnxm_lsthrx15_0']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"1% negative correlations ranking: {sorted(trainig_working_df.corr().quantile(0.1), reverse=True)}\")\n",
    "print(f\"99% negative correlations ranking: {sorted(trainig_working_df.corr().quantile(0.9), reverse=True)}\")\n",
    "trainig_working_df.corr().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box to do figure out which columns to use\n",
    "training_predictors_df = data_20191202_1200_working_df.copy()\n",
    "testing_predictors_df = data_20191203_1200_working_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(training_predictors_df.quantile(0.25) / training_predictors_df.quantile(0.01), reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(training_predictors_df.quantile(0.99) / training_predictors_df.quantile(0.75), reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(training_responses, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect influential points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use Mahalanobis distance, which computes distances from the data's centre and create an oval boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.mean(training_predictors_df, axis=0)\n",
    "cov_matrix = np.cov(training_predictors_df, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_distances = []\n",
    "for index, row in training_predictors_df.iterrows():\n",
    "    mahalanobis_distance = scipy.spatial.distance.mahalanobis(row, mean_vector, inv_cov_matrix)\n",
    "    mahalanobis_distances.append(mahalanobis_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df['mahalanobis_dist'] = mahalanobis_distances\n",
    "training_predictors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Need discussion\n",
    "mahal_threshold = 3 # Typical 'mahal_threshold' is 3\n",
    "outlier_significance_val = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df['mahal_p_value'] = 1 - scipy.stats.chi2.cdf(training_predictors_df['mahalanobis_dist'], mahal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_condition = (training_predictors_df['mahal_p_value'] < outlier_significance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonOutlier_indices = training_predictors_df[~outlier_condition].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_col = 'response'\n",
    "training_predictors_df[temp_col] = training_responses\n",
    "\n",
    "training_predictors_df = training_predictors_df[~outlier_condition]\n",
    "\n",
    "training_responses = training_predictors_df[temp_col]\n",
    "training_predictors_df.drop(temp_col, axis=COL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors_df.drop(['mahalanobis_dist', 'mahal_p_value'], axis = COL, inplace=True)\n",
    "training_predictors_df.reset_index(drop=True)\n",
    "training_predictors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge features and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([training_predictors_df, pd.DataFrame({consts.RESPONSE_NAME: training_responses})], \n",
    "                     axis=COL)\n",
    "test_df = pd.concat([testing_predictors_df, pd.DataFrame({consts.RESPONSE_NAME: testing_responses})], \n",
    "                    axis=COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '../data/cleaned_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train_filename = 'training_data.csv'\n",
    "out_test_filename = 'testing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(out_path + out_train_filename, index=False)\n",
    "test_df.to_csv(out_path + out_test_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > dependencies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = helper.get_file_names('20150101','20150601') # get filenames from before 6/1/2015\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(consts.DATA_PATH_2015 + f\"/{f}\") for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[-1].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat(dfs)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150601_1200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(consts.DATA_PATH_2015 + \"data.20150601_1200.csv\")\n",
    "x_cols = [\"rrirpnxm_nt_0\", \"rrirpnxm_lst15_0\",\"rrirpnxm_lsthrx15_0\", \"rrirpnxm_toxhr_0\"]\n",
    "saved_cols = x_cols + [RESPONSE_NAME]\n",
    "training_df = main_df[saved_cols]\n",
    "testing_df = test_df[saved_cols]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
